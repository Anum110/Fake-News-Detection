{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2334e679-5f25-467e-9c75-a641332d097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Sample:\n",
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "2  December 30, 2017  \n",
      "3  December 29, 2017  \n",
      "4  December 25, 2017  \n",
      "Original shape: (23481, 4)\n",
      "\n",
      "Real News Sample:\n",
      "                                               title  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "3  December 30, 2017   \n",
      "4  December 29, 2017   \n",
      "Original shape: (21417, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If the files are in a different folder, give the full path:\n",
    "fake_df = pd.read_csv(r\"C:\\Users\\anumf\\FakeNewApp\\fakeRealNewsDataset\\Fake.csv\")\n",
    "real_df = pd.read_csv(r\"C:\\Users\\anumf\\FakeNewApp\\fakeRealNewsDataset\\True.csv\")\n",
    "\n",
    "# Check the top few rows\n",
    "print(\"Fake News Sample:\")\n",
    "print(fake_df.head())\n",
    "print(\"Original shape:\", fake_df.shape)\n",
    "\n",
    "\n",
    "print(\"\\nReal News Sample:\")\n",
    "print(real_df.head())\n",
    "print(\"Original shape:\", real_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8191356-41f7-4227-90d4-bee5bfcd1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fake and real articles are in separate CSVs, we need to combine them into one DataFrame with a label column.\n",
    "fake_df[\"label\"] = 0  # 0 for fake\n",
    "real_df[\"label\"] = 1  # 1 for real\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_df, real_df], axis=0)\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e1a60b-de6a-4f2a-b607-79e0e4c0d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anumf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anumf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anumf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Clean and Preprocess the Text (Lowercasing, Removing punctuation, Removing stopwords, Stemming or Lemmatization)\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # remove punctuation\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # remove stopwords + lemmatize\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"text\"]  # Combine title and text\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b36690a3-61de-497d-8712-5b471905e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f76c57-1c30-4722-ad41-d93eee66fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Text (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1faacdda-2093-4589-b7c5-bd6263934698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9355233853006681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      4733\n",
      "           1       0.94      0.93      0.93      4247\n",
      "\n",
      "    accuracy                           0.94      8980\n",
      "   macro avg       0.94      0.94      0.94      8980\n",
      "weighted avg       0.94      0.94      0.94      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Classifier using Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625adb1a-0ab1-44f3-98cf-8ba32d2b0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9974387527839643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4733\n",
      "           1       1.00      1.00      1.00      4247\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_vec)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c8efa58-c773-4d7c-b568-d3bc021bac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9898663697104677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4733\n",
      "           1       0.99      0.99      0.99      4247\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_vec)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863c3e3b-3fe0-4971-89c4-5514536a1b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"fake_news_model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02983e-cdfc-4a26-a1e4-47f64de0ca07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
